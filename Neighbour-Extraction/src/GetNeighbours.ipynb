{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbour Extraction using Gram Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Helper import getDataLoader, getNames, dist\n",
    "from ipynb.fs.full.GramMatrix import convertModel, GramMatrixLayer\n",
    "from ipynb.fs.full.LabelDataset import createDirectories\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = getDataLoader('/scratch/bam_subset_2_0', batch_size=4, shuffle=False, num_workers=4, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramMatrixLayers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "vgg19, model, gram_matrices = convertModel(vgg19, gramMatrixLayers, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIter = iter(loader)\n",
    "\n",
    "(data, classes), names = dataIter.next()\n",
    "data = data.cuda()\n",
    "out = model(data)\n",
    "G = []\n",
    "for layer in gram_matrices:\n",
    "    G.append(layer.gramMatrix)\n",
    "G = torch.cat(G, 1)\n",
    "\n",
    "a, D = G.size()\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a ‘safe’ number of components to randomly project to\n",
    "\n",
    "The distortion introduced by a random projection p only changes the distance between two points by a factor (1 +- eps) in an euclidean space with good probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "\n",
    "# TODO: Remove hardcoded dataset size\n",
    "K = johnson_lindenstrauss_min_dim(121000, eps=0.3)\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import gaussian_random_matrix\n",
    "\n",
    "RPM = gaussian_random_matrix(K, D)\n",
    "RPM = RPM.transpose()\n",
    "print(RPM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/scratch/kshitij98'):\n",
    "    print(\"Creating\", '/scratch/kshitij98')\n",
    "    os.makedirs('/scratch/kshitij98')\n",
    "\n",
    "RPM = torch.from_numpy(RPM)\n",
    "RPM = RPM.cuda()\n",
    "RPM = RPM.float()\n",
    "print(RPM.shape)\n",
    "\n",
    "torch.save(RPM, \"/scratch/kshitij98/rpm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "createDirectories('/scratch/bam_subset_2_0_features/')\n",
    "\n",
    "dataIter = iter(loader)\n",
    "t = time.time()\n",
    "\n",
    "# TODO: Remove hardcoded dataset size\n",
    "for i in range(30250):\n",
    "    (data, classes), names = dataIter.next()\n",
    "    data = data.cuda()\n",
    "    out = model(data)\n",
    "    G = []\n",
    "    for layer in gram_matrices:\n",
    "        G.append(layer.gramMatrix)\n",
    "    G = torch.cat(G, 1)\n",
    "    G = torch.mm(G, RPM)\n",
    "    for j, gm in enumerate(G):\n",
    "        torch.save(gm, names[j].replace('bam_subset_2_0', 'bam_subset_2_0_features'))\n",
    "    print(i+1, \"\\tETA: \", ((time.time() - t) / ((i + 1) * 4)) * (121000 - ((i+1) * 4)) * (1 / 60), \"minutes\", end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "names = getNames('/scratch/bam_subset_2_0_features/')\n",
    "X = []\n",
    "for i, fileName in enumerate(names):\n",
    "    X.append(torch.load(fileName))\n",
    "    print(\"ETA: \", (len(names) - i - 1) * ((time.time() - t) / (i+1)), end='\\r')\n",
    "X = torch.stack(X, 0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDirectories('/scratch/bam_subset_2_0_top_neighbours/')\n",
    "createDirectories('/scratch/bam_subset_2_0_bottom_neighbours/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 15\n",
    "t = time.time()\n",
    "\n",
    "for i, source in enumerate(X):\n",
    "    source = torch.unsqueeze(source, 0)\n",
    "\n",
    "    d = dist(source, X)\n",
    "    d, indices = d.sort()\n",
    "\n",
    "    topIds = indices[0, 1:k+1]\n",
    "    # Note: Negative slicing is not supported\n",
    "    bottomIds = indices[0, -k:]\n",
    "\n",
    "    top = []\n",
    "    for idx in topIds:\n",
    "        top.append(names[idx])\n",
    "    top = np.asarray(top)\n",
    "    \n",
    "    bottom = []\n",
    "    for idx in bottomIds:\n",
    "        bottom.append(names[idx])\n",
    "    bottom = np.asarray(bottom)\n",
    "    \n",
    "    np.save(names[i].replace('bam_subset_2_0_features', 'bam_subset_2_0_top_neighbours'), top)\n",
    "    np.save(names[i].replace('bam_subset_2_0_features', 'bam_subset_2_0_bottom_neighbours'), bottom)\n",
    "\n",
    "    print(\"ETA: \", (len(X) - i - 1) * ((time.time() - t) / (i+1)) * (1 / 60), end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
