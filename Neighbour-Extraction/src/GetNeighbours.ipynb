{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbour Extraction using Gram Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Helper import getDataLoader\n",
    "from ipynb.fs.full.GramMatrix import convertModel, GramMatrixLayer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = getDataLoader('/scratch/bam_subset_2_0', batch_size=4, shuffle=False, num_workers=4, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramMatrixLayers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "vgg19, model, gram_matrices = convertModel(vgg19, gramMatrixLayers, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "RPM = np.random.normal(0, 1/1000, (610304, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = torch.from_numpy(RPM)\n",
    "RPM = RPM.cuda()\n",
    "RPM = RPM.float()\n",
    "print(RPM.shape)\n",
    "\n",
    "torch.save(RPM, \"/scratch/kshitij98/rpm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "dataIter = iter(loader)\n",
    "t = time.time()\n",
    "X = []\n",
    "for i in range(100):\n",
    "    (data, classes), names = dataIter.next()\n",
    "    data = data.cuda()\n",
    "    out = model(data)\n",
    "    G = []\n",
    "    for layer in gram_matrices:\n",
    "        G.append(layer.gramMatrix)\n",
    "    G = torch.cat(G, 1)\n",
    "    G = torch.mm(G, RPM)\n",
    "    for i, gm in enumerate(G):\n",
    "        torch.save(gm, names[i].replace('bam_subset_2_0', 'bam_subset_2_0_features')\n",
    "#     X.append(G)\n",
    "    print(i+1, \"\\tETA: \", ((time.time() - t) / ((i + 1) * 4)) * (121000 - ((i+1) * 4)) * (1 / 60), \"minutes\", end='\\r')\n",
    "# X = torch.cat(X, 0)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(X.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
